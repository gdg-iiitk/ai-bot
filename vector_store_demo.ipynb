{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Database(vdb) control:-\n",
    "\n",
    "This notebook demonstrates the usage of the vdb class for managing document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noelm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-15 23:15:51,291 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vdb_management import vdb\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAYew4okjx4jmR7xbKhLj2mAckgtUUbR-k\"\n",
    "# Initialize the vector store manager\n",
    "vector_store = vdb(persist_directory=\"db\")\n",
    "print(\"Vector store initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Files to the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 14:58:38,056 - INFO - Starting bulk addition of 6 files\n",
      "2025-01-15 14:58:38,058 - INFO - Processing file: ./data/mess_menu.txt\n",
      "2025-01-15 14:58:38,058 - INFO - Attempting to add file: ./data/mess_menu.txt\n",
      "2025-01-15 14:58:38,060 - WARNING - File already exists in database: ./data/mess_menu.txt\n",
      "2025-01-15 14:58:38,063 - INFO - Processing file: ./data/inst_ calender.txt\n",
      "2025-01-15 14:58:38,064 - INFO - Attempting to add file: ./data/inst_ calender.txt\n",
      "2025-01-15 14:58:38,066 - WARNING - File already exists in database: ./data/inst_ calender.txt\n",
      "2025-01-15 14:58:38,067 - INFO - Processing file: ./data/caricululm.txt\n",
      "2025-01-15 14:58:38,068 - INFO - Attempting to add file: ./data/caricululm.txt\n",
      "2025-01-15 14:58:38,071 - WARNING - File already exists in database: ./data/caricululm.txt\n",
      "2025-01-15 14:58:38,071 - INFO - Processing file: ./data/faculty_details.txt\n",
      "2025-01-15 14:58:38,071 - INFO - Attempting to add file: ./data/faculty_details.txt\n",
      "2025-01-15 14:58:38,074 - WARNING - File already exists in database: ./data/faculty_details.txt\n",
      "2025-01-15 14:58:38,075 - INFO - Processing file: ./data/milma_menu.txt\n",
      "2025-01-15 14:58:38,075 - INFO - Attempting to add file: ./data/milma_menu.txt\n",
      "2025-01-15 14:58:38,078 - WARNING - File already exists in database: ./data/milma_menu.txt\n",
      "2025-01-15 14:58:38,079 - INFO - Processing file: ./data/general_info.txt\n",
      "2025-01-15 14:58:38,081 - INFO - Attempting to add file: ./data/general_info.txt\n",
      "2025-01-15 14:58:38,082 - ERROR - Error adding file ./data/general_info.txt: Error loading ./data/general_info.txt\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\noelm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py\", line 43, in lazy_load\n",
      "    text = f.read()\n",
      "           ^^^^^^^^\n",
      "  File \"c:\\Users\\noelm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 264: character maps to <undefined>\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Noeland\\codialo\\ai-bot\\vdb_management.py\", line 50, in add_file\n",
      "    documents = loader.load()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\noelm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py\", line 31, in load\n",
      "    return list(self.lazy_load())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\noelm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py\", line 56, in lazy_load\n",
      "    raise RuntimeError(f\"Error loading {self.file_path}\") from e\n",
      "RuntimeError: Error loading ./data/general_info.txt\n",
      "2025-01-15 14:58:38,085 - INFO - Bulk addition completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bulk addition results:\n",
      "./data/mess_menu.txt: File ./data/mess_menu.txt already exists in the database\n",
      "./data/inst_ calender.txt: File ./data/inst_ calender.txt already exists in the database\n",
      "./data/caricululm.txt: File ./data/caricululm.txt already exists in the database\n",
      "./data/faculty_details.txt: File ./data/faculty_details.txt already exists in the database\n",
      "./data/milma_menu.txt: File ./data/milma_menu.txt already exists in the database\n",
      "./data/general_info.txt: Error adding file: Error loading ./data/general_info.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Add multiple files\n",
    "files_to_add = [\n",
    "    \"./data/mess_menu.txt\",\n",
    "    \"./data/inst_ calender.txt\",\n",
    "    \"./data/caricululm.txt\",\n",
    "    \"./data/faculty_details.txt\",\n",
    "    \"./data/milma_menu.txt\",\n",
    "    \"./data/general_info.txt\"\n",
    "]\n",
    "results = vector_store.bulk_add_files(files_to_add)\n",
    "print(\"\\nBulk addition results:\")\n",
    "for file, result in results.items():\n",
    "    print(f\"{file}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a single file\n",
    "result = vector_store.add_file(\"./data/sample.txt\")\n",
    "print(\"Single file addition result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAYew4okjx4jmR7xbKhLj2mAckgtUUbR-k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Files in the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in vector store:\n",
      "- C:\\Noeland\\codialo\\ai-bot\\data\\caricululm.txt\n",
      "- C:\\Noeland\\codialo\\ai-bot\\data\\faculty_details.txt\n",
      "- C:\\Noeland\\codialo\\ai-bot\\data\\inst_ calender.txt\n",
      "- C:\\Noeland\\codialo\\ai-bot\\data\\mess_menu.txt\n",
      "- C:\\Noeland\\codialo\\ai-bot\\data\\milma_menu.txt\n",
      "\n",
      "Detailed file information:\n",
      "\n",
      "File: C:\\Noeland\\codialo\\ai-bot\\data\\caricululm.txt\n",
      "Name: caricululm.txt\n",
      "Chunks: 5\n",
      "Added: 2025-01-14T15:11:19.709631\n",
      "\n",
      "File: C:\\Noeland\\codialo\\ai-bot\\data\\faculty_details.txt\n",
      "Name: faculty_details.txt\n",
      "Chunks: 54\n",
      "Added: 2025-01-14T15:11:22.917005\n",
      "\n",
      "File: C:\\Noeland\\codialo\\ai-bot\\data\\inst_ calender.txt\n",
      "Name: inst_ calender.txt\n",
      "Chunks: 3\n",
      "Added: 2025-01-14T15:11:23.571139\n",
      "\n",
      "File: C:\\Noeland\\codialo\\ai-bot\\data\\mess_menu.txt\n",
      "Name: mess_menu.txt\n",
      "Chunks: 4\n",
      "Added: 2025-01-14T15:11:24.991150\n",
      "\n",
      "File: C:\\Noeland\\codialo\\ai-bot\\data\\milma_menu.txt\n",
      "Name: milma_menu.txt\n",
      "Chunks: 2\n",
      "Added: 2025-01-14T15:11:25.598637\n"
     ]
    }
   ],
   "source": [
    "# List files (simple)\n",
    "files = vector_store.list_files()\n",
    "print(\"Files in vector store:\")\n",
    "for file in files:\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "# List files with details\n",
    "detailed_files = vector_store.list_files(detailed=True)\n",
    "print(\"\\nDetailed file information:\")\n",
    "for path, info in detailed_files.items():\n",
    "    print(f\"\\nFile: {path}\")\n",
    "    print(f\"Name: {info['file_name']}\")\n",
    "    print(f\"Chunks: {info['chunk_count']}\")\n",
    "    print(f\"Added: {info['added_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching Similar Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for: 'What's on the mess menu for lunch?'\n",
      "\n",
      "Result 1:\n",
      "Content: MESS MENU \n",
      "\n",
      "Monday\n",
      "\n",
      "Breakfast: Vada Pav, Puttu, Channa Curry, Fried Chillies, Onions, Green Chutney, Red Powdered Chutney, Bread (Normal/Brown), Jam, Butter, Tea, Milk, Banana\n",
      "\n",
      "Lunch: Jeera Rice, Kera...\n",
      "Metadata: {'source': './data/mess_menu.txt'}\n",
      "Similarity: None\n",
      "\n",
      "Result 2:\n",
      "Content: Wednesday\n",
      "\n",
      "Breakfast: Idli, Masala Idli, Punugulu, Sambar, Groundnut Chutney, Tomato Chutney, Bread (Normal/Brown), Jam, Butter, Coffee, Milk\n",
      "\n",
      "Lunch: Rice, Roti, Palak Dal Tadka, Crunchy Bhindi Fry, R...\n",
      "Metadata: {'source': './data/mess_menu.txt'}\n",
      "Similarity: None\n",
      "\n",
      "Result 3:\n",
      "Content: Friday\n",
      "\n",
      "Breakfast: Idli, Masala Idli, Medu Vada, Groundnut Chutney, Tomato Chutney, Sambar, Bread (Normal/Brown), Jam, Butter, Tea, Milk\n",
      "\n",
      "Lunch: Rice, Tomato Rice, Roti, Beans and Carrot Thoran, Chana...\n",
      "Metadata: {'source': './data/mess_menu.txt'}\n",
      "Similarity: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for similar content\n",
    "query = \"What's on the mess menu for lunch?\"\n",
    "results = vector_store.search_similar(query, k=3)\n",
    "\n",
    "print(f\"Search results for: '{query}'\\n\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"Content: {result['content'][:200]}...\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    print(f\"Similarity: {result['similarity']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection stats\n",
    "stats = vector_store.get_collection_stats()\n",
    "print(f\"Total documents: {stats['total_documents']}\")\n",
    "print(f\"Total files: {stats['total_files']}\")\n",
    "print(\"\\nFiles in collection:\")\n",
    "for path, info in stats['files'].items():\n",
    "    print(f\"\\n{info['file_name']}:\")\n",
    "    print(f\"- Chunks: {info['chunk_count']}\")\n",
    "    print(f\"- Added: {info['added_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a file\n",
    "file_to_remove = \"./data/sample.txt\"\n",
    "result = vector_store.remove_file(file_to_remove)\n",
    "print(f\"Removal result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize from a directory\n",
    "results = vector_store.initialize_from_directory(\"./data\", glob_pattern=\"**/*.txt\")\n",
    "print(\"Directory initialization results:\")\n",
    "for file, result in results.items():\n",
    "    print(f\"{file}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the database (use with caution)\n",
    "# result = vector_store.clear_database()\n",
    "# print(f\"Database cleanup result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
